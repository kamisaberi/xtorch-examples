// #include <torch/torch.h>
// #include <fstream>
// #include <iostream>
// #include <vector>
// #include <string>
//
// // Residual Block for Generator
// struct ResidualBlock : torch::nn::Module {
//     ResidualBlock(int64_t channels)
//         : conv1(torch::nn::Conv2dOptions(channels, channels, 3).padding(1)),
//           conv2(torch::nn::Conv2dOptions(channels, channels, 3).padding(1)),
//           norm1(channels), norm2(channels) {
//         register_module("conv1", conv1);
//         register_module("conv2", conv2);
//         register_module("norm1", norm1);
//         register_module("norm2", norm2);
//     }
//
//     torch::Tensor forward(torch::Tensor x) {
//         auto out = torch::relu(norm1->forward(conv1->forward(x)));
//         out = norm2->forward(conv2->forward(out));
//         return x + out; // Residual connection
//     }
//
//     torch::nn::Conv2d conv1, conv2;
//     torch::nn::InstanceNorm2d norm1, norm2;
// };
//
// // Generator: ResNet-based (6 residual blocks)
// struct Generator : torch::nn::Module {
//     Generator()
//         : conv_in(torch::nn::Conv2dOptions(1, 64, 7).padding(3)),
//           norm_in(64),
//           conv_down1(torch::nn::Conv2dOptions(64, 128, 3).stride(2).padding(1)),
//           norm_down1(128),
//           conv_down2(torch::nn::Conv2dOptions(128, 256, 3).stride(2).padding(1)),
//           norm_down2(256),
//           res1(256), res2(256), res3(256), res4(256), res5(256), res6(256),
//           conv_up1(torch::nn::ConvTranspose2dOptions(256, 128, 3).stride(2).padding(1).output_padding(1)),
//           norm_up1(128),
//           conv_up2(torch::nn::ConvTranspose2dOptions(128, 64, 3).stride(2).padding(1).output_padding(1)),
//           norm_up2(64),
//           conv_out(torch::nn::Conv2dOptions(64, 1, 7).padding(3)) {
//         register_module("conv_in", conv_in);
//         register_module("norm_in", norm_in);
//         register_module("conv_down1", conv_down1);
//         register_module("norm_down1", norm_down1);
//         register_module("conv_down2", conv_down2);
//         register_module("norm_down2", norm_down2);
//         register_module("res1", res1);
//         register_module("res2", res2);
//         register_module("res3", res3);
//         register_module("res4", res4);
//         register_module("res5", res5);
//         register_module("res6", res6);
//         register_module("conv_up1", conv_up1);
//         register_module("norm_up1", norm_up1);
//         register_module("conv_up2", conv_up2);
//         register_module("norm_up2", norm_up2);
//         register_module("conv_out", conv_out);
//     }
//
//     torch::Tensor forward(torch::Tensor x) {
//         auto out = torch::relu(norm_in->forward(conv_in->forward(x)));
//         out = torch::relu(norm_down1->forward(conv_down1->forward(out)));
//         out = torch::relu(norm_down2->forward(conv_down2->forward(out)));
//         out = res1->forward(out);
//         out = res2->forward(out);
//         out = res3->forward(out);
//         out = res4->forward(out);
//         out = res5->forward(out);
//         out = res6->forward(out);
//         out = torch::relu(norm_up1->forward(conv_up1->forward(out)));
//         out = torch::relu(norm_up2->forward(conv_up2->forward(out)));
//         out = torch::tanh(conv_out->forward(out));
//         return out;
//     }
//
//     torch::nn::Conv2d conv_in, conv_out;
//     torch::nn::Conv2d conv_down1, conv_down2;
//     torch::nn::ConvTranspose2d conv_up1, conv_up2;
//     torch::nn::InstanceNorm2d norm_in, norm_down1, norm_down2, norm_up1, norm_up2;
//     ResidualBlock res1, res2, res3, res4, res5, res6;
// };
//
// // Discriminator: PatchGAN
// struct Discriminator : torch::nn::Module {
//     Discriminator()
//         : conv1(torch::nn::Conv2dOptions(1, 64, 4).stride(2).padding(1)),
//           conv2(torch::nn::Conv2dOptions(64, 128, 4).stride(2).padding(1)),
//           norm2(128),
//           conv3(torch::nn::Conv2dOptions(128, 256, 4).stride(2).padding(1)),
//           norm3(256),
//           conv4(torch::nn::Conv2dOptions(256, 1, 4).padding(1)) {
//         register_module("conv1", conv1);
//         register_module("conv2", conv2);
//         register_module("norm2", norm2);
//         register_module("conv3", conv3);
//         register_module("norm3", norm3);
//         register_module("conv4", conv4);
//     }
//
//     torch::Tensor forward(torch::Tensor x) {
//         auto out = torch::leaky_relu(conv1->forward(x), 0.2);
//         out = torch::leaky_relu(norm2->forward(conv2->forward(out)), 0.2);
//         out = torch::leaky_relu(norm3->forward(conv3->forward(out)), 0.2);
//         out = conv4->forward(out);
//         return out;
//     }
//
//     torch::nn::Conv2d conv1, conv2, conv3, conv4;
//     torch::nn::InstanceNorm2d norm2, norm3;
// };
//
// // Read MNIST image
// std::vector<float> read_mnist_image(const std::string& path, int idx) {
//     std::ifstream file(path, std::ios::binary);
//     if (!file) {
//         std::cerr << "Failed to open MNIST file: " << path << std::endl;
//         return {};
//     }
//     file.seekg(16 + idx * 28 * 28); // Skip header
//     std::vector<float> img(28 * 28);
//     for (int i = 0; i < 28 * 28; ++i) {
//         unsigned char pixel;
//         file.read((char*)&pixel, 1);
//         img[i] = pixel / 255.0f * 2.0f - 1.0f; // Normalize to [-1, 1]
//     }
//     return img;
// }
//
// // Resize 28x28 to 64x64 (bilinear interpolation)
// std::vector<float> resize_28x28_to_64x64(const std::vector<float>& input) {
//     std::vector<float> output(64 * 64, 0.0f);
//     float scale = 64.0f / 28.0f;
//     for (int y = 0; y < 64; ++y) {
//         for (int x = 0; x < 64; ++x) {
//             float src_x = x / scale;
//             float src_y = y / scale;
//             int x0 = static_cast<int>(src_x);
//             int y0 = static_cast<int>(src_y);
//             int x1 = std::min(x0 + 1, 27);
//             int y1 = std::min(y0 + 1, 27);
//             float dx = src_x - x0;
//             float dy = src_y - y0;
//
//             float val = (1 - dx) * (1 - dy) * input[y0 * 28 + x0] +
//                         dx * (1 - dy) * input[y0 * 28 + x1] +
//                         (1 - dx) * dy * input[y1 * 28 + x0] +
//                         dx * dy * input[y1 * 28 + x1];
//             output[y * 64 + x] = val;
//         }
//     }
//     return output;
// }
//
// // Generate synthetic stylized image (placeholder)
// std::vector<float> generate_stylized_image() {
//     std::vector<float> img(64 * 64);
//     std::random_device rd;
//     std::mt19937 gen(rd());
//     std::normal_distribution<float> dist(0.0f, 0.5f);
//     for (size_t i = 0; i < 64 * 64; ++i) {
//         img[i] = std::clamp(dist(gen), -1.0f, 1.0f); // Random noise, [-1, 1]
//     }
//     return img;
// }
//
// int main() {
//     // Set device
//     torch::Device device(torch::kCUDA);
//     if (!torch::cuda::is_available()) {
//         std::cerr << "CUDA not available, using CPU." << std::endl;
//         device = torch::Device(torch::kCPU);
//     }
//
//     // Initialize models
//     Generator G, F;
//     Discriminator D_X, D_Y;
//     G->to(device);
//     F->to(device);
//     D_X->to(device);
//     D_Y->to(device);
//
//     // Optimizers
//     auto optim_G = torch::optim::Adam(torch::nn::parameters({G, F}), torch::optim::AdamOptions(2e-4).betas({0.5, 0.999}));
//     auto optim_D = torch::optim::Adam(torch::nn::parameters({D_X, D_Y}), torch::optim::AdamOptions(2e-4).betas({0.5, 0.999}));
//
//     // Loss functions
//     auto gan_loss = [](torch::Tensor pred, bool is_real) {
//         auto target = is_real ? torch::ones_like(pred) : torch::zeros_like(pred);
//         return torch::mse_loss(pred, target);
//     };
//     auto cycle_loss = [](torch::Tensor x, torch::Tensor recon_x) {
//         return torch::l1_loss(x, recon_x);
//     };
//
//     // Training loop (minimal demo)
//     const int num_epochs = 1; // Increase for real training
//     const float lambda_cycle = 10.0f;
//     for (int epoch = 0; epoch < num_epochs; ++epoch) {
//         // Load data
//         auto real_x = read_mnist_image("train-images-idx3-ubyte", epoch % 60000);
//         if (real_x.empty()) {
//             std::cerr << "Failed to load MNIST image." << std::endl;
//             continue;
//         }
//         auto real_x_64 = resize_28x28_to_64x64(real_x);
//         auto real_y = generate_stylized_image();
//
//         // Convert to tensors
//         auto x_tensor = torch::from_blob(real_x_64.data(), {1, 1, 64, 64}, torch::kFloat).to(device);
//         auto y_tensor = torch::from_blob(real_y.data(), {1, 1, 64, 64}, torch::kFloat).to(device);
//
//         // Train Discriminators
//         optim_D.zero_grad();
//         auto fake_y = G->forward(x_tensor);
//         auto D_Y_real = D_Y->forward(y_tensor);
//         auto D_Y_fake = D_Y->forward(fake_y.detach());
//         auto loss_D_Y = gan_loss(D_Y_real, true) + gan_loss(D_Y_fake, false);
//         auto fake_x = F->forward(y_tensor);
//         auto D_X_real = D_X->forward(x_tensor);
//         auto D_X_fake = D_X->forward(fake_x.detach());
//         auto loss_D_X = gan_loss(D_X_real, true) + gan_loss(D_X_fake, false);
//         auto loss_D = (loss_D_X + loss_D_Y) / 2;
//         loss_D.backward();
//         optim_D.step();
//
//         // Train Generators
//         optim_G.zero_grad();
//         fake_y = G->forward(x_tensor);
//         auto recon_x = F->forward(fake_y);
//         fake_x = F->forward(y_tensor);
//         auto recon_y = G->forward(fake_x);
//         auto loss_G_gan = gan_loss(D_Y->forward(fake_y), true);
//         auto loss_F_gan = gan_loss(D_X->forward(fake_x), true);
//         auto loss_cycle_x = cycle_loss(x_tensor, recon_x) * lambda_cycle;
//         auto loss_cycle_y = cycle_loss(y_tensor, recon_y) * lambda_cycle;
//         auto loss_G = loss_G_gan + loss_F_gan + loss_cycle_x + loss_cycle_y;
//         loss_G.backward();
//         optim_G.step();
//
//         std::cout << "[Epoch " << epoch << "] D Loss: " << loss_D.item<float>()
//                   << ", G Loss: " << loss_G.item<float>() << std::endl;
//
//         // Save generated image
//         auto cpu_fake_y = fake_y.cpu().detach().contiguous();
//         std::ofstream out("fake_y_" + std::to_string(epoch) + ".raw", std::ios::binary);
//         auto data = cpu_fake_y.data_ptr<float>();
//         for (size_t i = 0; i < 64 * 64; ++i) {
//             unsigned char pixel = static_cast<unsigned char>((data[i] + 1.0f) * 127.5f);
//             out.write((char*)&pixel, 1);
//         }
//         out.close();
//     }
//
//     std::cout << "Saved generated images as fake_y_<epoch>.raw (64x64 grayscale)" << std::endl;
//     return 0;
// }

